#!/usr/bin/env python3
"""
Enhance Interactive Feature Circuit Visualization with comprehensive documentation.

This script updates the circuit visualization cells with:
- Comprehensive theory and mathematical formulas
- PEP-8 style docstrings
- Research context and references
"""
import json
from pathlib import Path


# Enhanced cells with comprehensive documentation
ENHANCED_CELLS = [
    {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "---\n",
            "\n",
            "## 9. Interactive Feature Circuit Visualization\n",
            "\n",
            "### Theoretical Foundation: Compositional Feature Hierarchies\n",
            "\n",
            "The **Circuits** research thread from Distill.pub (Olah et al., 2020) demonstrates that\n",
            "neural networks learn *compositional representations* where features in later layers\n",
            "are built from combinations of features in earlier layers.\n",
            "\n",
            "#### Mathematical Framework\n",
            "\n",
            "For a layer $l$, the activation of neuron $k$ can be expressed as:\n",
            "\n",
            "$$a_{l,k}(\\mathbf{x}) = \\sigma\\left(\\sum_{j} w_{jk}^{(l)} \\cdot a_{l-1,j}(\\mathbf{x}) + b_k^{(l)}\\right)$$\n",
            "\n",
            "where:\n",
            "- $a_{l,k}$ = Activation of neuron $k$ at layer $l$\n",
            "- $w_{jk}^{(l)}$ = Weight connecting neuron $j$ (layer $l-1$) to neuron $k$ (layer $l$)\n",
            "- $\\sigma$ = Non-linear activation function (ReLU)\n",
            "- $b_k^{(l)}$ = Bias term\n",
            "\n",
            "#### The Polysemantic Neuron Hypothesis\n",
            "\n",
            "Individual neurons often respond to multiple, seemingly unrelated concepts.\n",
            "However, when examined as **circuits** (connected groups of neurons), they reveal\n",
            "interpretable algorithms.\n",
            "\n",
            "### Feature Hierarchy in InceptionV1\n",
            "\n",
            "| Layer | Receptive Field | Feature Complexity | Typical Detections |\n",
            "|-------|----------------|-------------------|-------------------|\n",
            "| `conv2d1` | 7Ã—7 | Low | Edges, colors, gradients |\n",
            "| `mixed3a` | ~35Ã—35 | Medium-Low | Gabor filters, textures |\n",
            "| `mixed3b` | ~55Ã—55 | Medium | Complex textures, curves |\n",
            "| `mixed4a` | ~107Ã—107 | Medium-High | Object parts, shapes |\n",
            "| `mixed5b` | ~224Ã—224 | High | Full objects, scenes |\n",
            "\n",
            "### Circuit Example: The Car Detector\n",
            "\n",
            "From the Distill.pub [Zoom In](https://distill.pub/2020/circuits/zoom-in/) article:\n",
            "\n",
            "```\n",
            "Windows (4b:237)  â”€â”\n",
            "                   â”œâ”€â”€â†’  Car Detector (4c:447)\n",
            "Car Body (4b:491) â”€â”¤\n",
            "                   â”‚\n",
            "Wheels (4b:373)  â”€â”€â”˜\n",
            "```\n",
            "\n",
            "Each component neuron **excites** or **inhibits** the target detector based on\n",
            "spatial relationships (e.g., wheels excite the bottom of the car detector).\n",
            "\n",
            "### Visualization Goals\n",
            "\n",
            "1. **Plotly Grid**: Interactive hover showing feature descriptions\n",
            "2. **Distill-Style Diagram**: Visual flow from early to late layers\n",
            "\n",
            "**References:**\n",
            "- Olah et al., *Zoom In: An Introduction to Circuits*, Distill 2020\n",
            "- Olah et al., *An Overview of Early Vision*, Distill 2020\n"
        ]
    },
    {
        "cell_type": "code",
        "metadata": {},
        "execution_count": None,
        "outputs": [],
        "source": [
            "r\"\"\"\n",
            "Generate feature visualizations across multiple layers for circuit analysis.\n",
            "\n",
            "This module creates activation maximization images for neurons at different\n",
            "depths in InceptionV1, demonstrating how features compose hierarchically.\n",
            "\n",
            "Mathematical Background:\n",
            "------------------------\n",
            "For each neuron, we find the input that maximizes its activation:\n",
            "\n",
            "    x* = argmax_x mean(A_k(f(x)))\n",
            "\n",
            "where A_k is the activation map for channel k.\n",
            "\n",
            "Layer Selection Rationale:\n",
            "-------------------------\n",
            "- conv2d1: First conv layer, learns edge/color primitives\n",
            "- mixed3a: First Inception module, Gabor-like textures\n",
            "- mixed3b: Second Inception, complex texture compositions\n",
            "- mixed4a: Third Inception, object parts emerge\n",
            "\n",
            "References:\n",
            "    Olah et al., \"Zoom In: An Introduction to Circuits\", Distill 2020\n",
            "    https://distill.pub/2020/circuits/zoom-in/\n",
            "\"\"\"\n",
            "\n",
            "# Layer configuration for circuit analysis\n",
            "# Each layer represents a different level of the feature hierarchy\n",
            "CIRCUIT_LAYERS = {\n",
            "    'conv2d1': {\n",
            "        'indices': [0, 1, 2, 3],\n",
            "        'desc': 'Early vision: basic edge and color detectors',\n",
            "        'receptive_field': '7Ã—7 pixels'\n",
            "    },\n",
            "    'mixed3a': {\n",
            "        'indices': [0, 1, 2, 3],\n",
            "        'desc': 'Gabor-like oriented edge detectors',\n",
            "        'receptive_field': '~35Ã—35 pixels'\n",
            "    },\n",
            "    'mixed3b': {\n",
            "        'indices': [0, 1, 2, 3],\n",
            "        'desc': 'Complex texture and curve detectors',\n",
            "        'receptive_field': '~55Ã—55 pixels'\n",
            "    },\n",
            "    'mixed4a': {\n",
            "        'indices': [0, 1, 2, 3],\n",
            "        'desc': 'Object parts: boundaries, shapes, parts',\n",
            "        'receptive_field': '~107Ã—107 pixels'\n",
            "    },\n",
            "}\n",
            "\n",
            "# Feature metadata: human-interpretable descriptions for each neuron\n",
            "# Based on visual inspection and Distill.pub feature families\n",
            "FEATURE_METADATA = {\n",
            "    # Early vision (conv2d1) - Corresponds to V1-like features\n",
            "    'conv2d1:0': 'Low-frequency detector: responds to smooth gradients and large-scale brightness changes',\n",
            "    'conv2d1:1': 'High-frequency detector: responds to fine textures and sharp transitions',\n",
            "    'conv2d1:2': 'Color opponent (R-G): red-green channel, similar to retinal ganglion cells',\n",
            "    'conv2d1:3': 'Color opponent (B-Y): blue-yellow channel, fundamental color processing',\n",
            "    \n",
            "    # Gabor-like (mixed3a) - Similar to V1 simple cells\n",
            "    'mixed3a:0': 'Horizontal edge: responds to horizontal oriented boundaries (0Â°)',\n",
            "    'mixed3a:1': 'Diagonal edge (45Â°): responds to edges at 45Â° orientation',\n",
            "    'mixed3a:2': 'Vertical edge: responds to vertical oriented boundaries (90Â°)',\n",
            "    'mixed3a:3': 'Texture detector: responds to regular repeating patterns',\n",
            "    \n",
            "    # Complex textures (mixed3b) - V2/V4-like features\n",
            "    'mixed3b:0': 'Curve detector: responds to curved contours and arcs',\n",
            "    'mixed3b:1': 'Corner/junction: responds to L-shapes and T-junctions',\n",
            "    'mixed3b:2': 'Grid pattern: responds to regular lattice structures',\n",
            "    'mixed3b:3': 'Organic texture: responds to natural textures (fur, foliage)',\n",
            "    \n",
            "    # Object parts (mixed4a) - IT-like features\n",
            "    'mixed4a:0': 'Silhouette boundary: responds to object outlines against backgrounds',\n",
            "    'mixed4a:1': 'Window-like: responds to rectangular frames and window patterns',\n",
            "    'mixed4a:2': 'Circular/wheel: responds to round objects and wheel-like shapes',\n",
            "    'mixed4a:3': 'Face parts: responds to eye-like or facial feature patterns',\n",
            "}\n",
            "\n",
            "\n",
            "def generate_circuit_visualizations(\n",
            "    model: torch.nn.Module,\n",
            "    layers: dict,\n",
            "    image_size: int = 96,\n",
            "    num_steps: int = 256\n",
            ") -> dict:\n",
            "    r\"\"\"\n",
            "    Generate activation maximization images for neurons across multiple layers.\n",
            "    \n",
            "    This function creates visualizations that reveal what each neuron has learned\n",
            "    to detect, enabling analysis of the compositional feature hierarchy.\n",
            "    \n",
            "    Mathematical Background:\n",
            "        The optimization finds x* such that:\n",
            "        \n",
            "        x* = argmax_x [ mean(A_k(f(x))) - Î»_TV * L_TV(x) - Î»_L2 * ||x||Â² ]\n",
            "        \n",
            "        where A_k is the k-th channel activation and L_TV is total variation.\n",
            "    \n",
            "    Args:\n",
            "        model: Pre-trained InceptionV1 model (frozen weights)\n",
            "        layers: Dict mapping layer names to config dicts with 'indices' key\n",
            "        image_size: Output image resolution (default: 96 for speed)\n",
            "        num_steps: Gradient ascent iterations (more = cleaner features)\n",
            "    \n",
            "    Returns:\n",
            "        dict: Mapping 'layer:neuron_idx' -> numpy array (H, W, 3)\n",
            "    \n",
            "    Example:\n",
            "        >>> images = generate_circuit_visualizations(model, CIRCUIT_LAYERS)\n",
            "        >>> images['mixed4a:0'].shape  # (96, 96, 3)\n",
            "    \n",
            "    Notes:\n",
            "        - Uses FFT parameterization for natural-looking images\n",
            "        - Decorrelated color space prevents adversarial patterns\n",
            "        - Lower num_steps trades quality for speed\n",
            "    \n",
            "    References:\n",
            "        Mordvintsev et al., \"Differentiable Image Parameterizations\", Distill 2018\n",
            "    \"\"\"\n",
            "    circuit_images = {}\n",
            "    \n",
            "    # FFT parameterization with decorrelated colors\n",
            "    # This produces more natural, interpretable visualizations\n",
            "    param_f = lambda: param.image(image_size, fft=True, decorrelate=True)\n",
            "    \n",
            "    total_neurons = sum(len(cfg['indices']) for cfg in layers.values())\n",
            "    current = 0\n",
            "    \n",
            "    for layer_name, config in layers.items():\n",
            "        print(f\"\\nðŸ“Š Layer: {layer_name}\")\n",
            "        print(f\"   Description: {config['desc']}\")\n",
            "        print(f\"   Receptive field: {config.get('receptive_field', 'N/A')}\")\n",
            "        \n",
            "        for idx in config['indices']:\n",
            "            current += 1\n",
            "            key = f\"{layer_name}:{idx}\"\n",
            "            print(f\"   [{current}/{total_neurons}] {key} ... \", end=\"\", flush=True)\n",
            "            \n",
            "            try:\n",
            "                # Run activation maximization\n",
            "                images = render.render_vis(\n",
            "                    model, key,\n",
            "                    param_f=param_f,\n",
            "                    thresholds=(num_steps,),\n",
            "                    show_image=False,\n",
            "                    verbose=False\n",
            "                )\n",
            "                circuit_images[key] = images[0][0]\n",
            "                print(\"âœ“\")\n",
            "            except Exception as e:\n",
            "                print(f\"âœ— (Error: {str(e)[:50]})\")\n",
            "                # Return blank image on failure\n",
            "                circuit_images[key] = np.zeros((image_size, image_size, 3))\n",
            "    \n",
            "    return circuit_images\n",
            "\n",
            "\n",
            "# Generate circuit visualizations\n",
            "print(\"=\"*70)\n",
            "print(\"GENERATING FEATURE CIRCUIT VISUALIZATIONS\")\n",
            "print(\"=\"*70)\n",
            "print(\"\\nThis generates activation maximization images for neurons across\")\n",
            "print(\"multiple layers, revealing the compositional feature hierarchy.\")\n",
            "print(\"\\nLayers: conv2d1 â†’ mixed3a â†’ mixed3b â†’ mixed4a\")\n",
            "print(\"-\"*70)\n",
            "\n",
            "circuit_images = generate_circuit_visualizations(\n",
            "    model, CIRCUIT_LAYERS,\n",
            "    image_size=96,   # Smaller for speed; use 128+ for publication quality\n",
            "    num_steps=256    # Fewer steps for speed; use 512+ for cleaner features\n",
            ")\n",
            "\n",
            "print(\"\\n\" + \"=\"*70)\n",
            "print(f\"âœ… Generated {len(circuit_images)} feature visualizations\")\n",
            "print(\"=\"*70)\n"
        ]
    },
    {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "### Option A: Interactive Plotly Grid\n",
            "\n",
            "**How to use:** Hover over each image to see:\n",
            "- Layer and neuron index\n",
            "- Human-interpretable feature description\n",
            "- Biological analogy (V1, V2, IT cortex correspondence)\n",
            "\n",
            "**Interpretation Guide:**\n",
            "- **Left columns** (conv2d1): Edge and color primitives, similar to V1\n",
            "- **Middle columns** (mixed3a/b): Texture and pattern detectors, similar to V2/V4\n",
            "- **Right columns** (mixed4a): Object parts, similar to IT cortex\n"
        ]
    },
    {
        "cell_type": "code",
        "metadata": {},
        "execution_count": None,
        "outputs": [],
        "source": [
            "r\"\"\"\n",
            "Create interactive Plotly visualization with hover tooltips.\n",
            "\n",
            "This visualization allows exploring the feature hierarchy interactively.\n",
            "Hovering over each feature image displays:\n",
            "- Neuron identifier (layer:index)\n",
            "- Human-interpretable description\n",
            "- Feature family classification\n",
            "\n",
            "Implementation Notes:\n",
            "--------------------\n",
            "Plotly is chosen for Jupyter/Colab compatibility without additional\n",
            "JavaScript dependencies. The go.Image trace with custom hovertemplate\n",
            "provides native hover interactivity.\n",
            "\n",
            "References:\n",
            "    Plotly documentation: https://plotly.com/python/hover-text-and-formatting/\n",
            "\"\"\"\n",
            "\n",
            "import plotly.graph_objects as go\n",
            "from plotly.subplots import make_subplots\n",
            "\n",
            "\n",
            "def create_plotly_circuit_grid(\n",
            "    images: dict,\n",
            "    metadata: dict,\n",
            "    layers: dict,\n",
            "    title: str = \"Feature Circuit Hierarchy\"\n",
            ") -> go.Figure:\n",
            "    r\"\"\"\n",
            "    Create an interactive Plotly grid visualization of feature circuits.\n",
            "    \n",
            "    The grid is organized with:\n",
            "    - Columns: Layers (early â†’ late, left â†’ right)\n",
            "    - Rows: Different neurons within each layer\n",
            "    \n",
            "    Args:\n",
            "        images: Dict mapping 'layer:idx' to numpy image arrays\n",
            "        metadata: Dict mapping 'layer:idx' to description strings\n",
            "        layers: Dict of layer configurations\n",
            "        title: Title for the figure\n",
            "    \n",
            "    Returns:\n",
            "        go.Figure: Interactive Plotly figure with hover tooltips\n",
            "    \n",
            "    Example:\n",
            "        >>> fig = create_plotly_circuit_grid(images, metadata, layers)\n",
            "        >>> fig.show()  # Opens interactive visualization\n",
            "    \"\"\"\n",
            "    layer_names = list(layers.keys())\n",
            "    n_layers = len(layer_names)\n",
            "    n_neurons = max(len(cfg['indices']) for cfg in layers.values())\n",
            "    \n",
            "    # Create subplot grid: columns=layers, rows=neurons\n",
            "    fig = make_subplots(\n",
            "        rows=n_neurons, cols=n_layers,\n",
            "        subplot_titles=[f\"<b>{ln}</b><br><sup>{layers[ln]['desc'][:30]}...</sup>\" \n",
            "                       for ln in layer_names],\n",
            "        horizontal_spacing=0.03,\n",
            "        vertical_spacing=0.08,\n",
            "    )\n",
            "    \n",
            "    for col, layer_name in enumerate(layer_names, 1):\n",
            "        for row, idx in enumerate(layers[layer_name]['indices'], 1):\n",
            "            key = f\"{layer_name}:{idx}\"\n",
            "            img = images.get(key)\n",
            "            \n",
            "            if img is not None:\n",
            "                # Convert to uint8 for display\n",
            "                img_uint8 = (np.clip(img, 0, 1) * 255).astype(np.uint8)\n",
            "                desc = metadata.get(key, 'No description available')\n",
            "                \n",
            "                fig.add_trace(\n",
            "                    go.Image(\n",
            "                        z=img_uint8,\n",
            "                        hovertemplate=(\n",
            "                            f\"<b style='font-size:14px'>{key}</b><br><br>\"\n",
            "                            f\"{desc}<br>\"\n",
            "                            f\"<extra></extra>\"\n",
            "                        ),\n",
            "                    ),\n",
            "                    row=row, col=col\n",
            "                )\n",
            "    \n",
            "    # Update layout for clean appearance\n",
            "    fig.update_layout(\n",
            "        title={\n",
            "            'text': f'<b>{title}</b><br><sup>Hover over images for feature descriptions</sup>',\n",
            "            'x': 0.5,\n",
            "            'font': {'size': 18}\n",
            "        },\n",
            "        height=700,\n",
            "        width=1000,\n",
            "        showlegend=False,\n",
            "        paper_bgcolor='#f8f9fa',\n",
            "        plot_bgcolor='#f8f9fa',\n",
            "    )\n",
            "    \n",
            "    # Hide axes for cleaner look\n",
            "    fig.update_xaxes(showticklabels=False, showgrid=False, zeroline=False)\n",
            "    fig.update_yaxes(showticklabels=False, showgrid=False, zeroline=False)\n",
            "    \n",
            "    return fig\n",
            "\n",
            "\n",
            "# Create and display the interactive Plotly grid\n",
            "print(\"Creating interactive Plotly visualization...\")\n",
            "plotly_fig = create_plotly_circuit_grid(\n",
            "    circuit_images,\n",
            "    FEATURE_METADATA,\n",
            "    CIRCUIT_LAYERS,\n",
            "    title=\"Feature Circuit: conv2d1 â†’ mixed3a â†’ mixed3b â†’ mixed4a\"\n",
            ")\n",
            "plotly_fig.show()\n",
            "print(\"\\nðŸ’¡ Tip: Hover over each image to see what the neuron detects!\")\n"
        ]
    },
    {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "### Option B: Distill-Style Circuit Diagram\n",
            "\n",
            "This visualization mimics the style from Distill.pub's *Circuits* articles,\n",
            "showing the flow from early features to later, more complex features.\n",
            "\n",
            "#### Visual Elements:\n",
            "\n",
            "| Element | Meaning |\n",
            "|---------|--------|\n",
            "| **â†’ Arrows** | Information flow (features feed into later layers) |\n",
            "| **ðŸ”´ Red** | Positive influence (excitation) |\n",
            "| **ðŸ”µ Blue** | Negative influence (inhibition) |\n",
            "| **Hover tooltip** | Feature description and layer info |\n",
            "\n",
            "#### Biological Correspondence:\n",
            "\n",
            "The architecture mirrors the ventral visual stream:\n",
            "- **conv2d1** â‰ˆ Primary Visual Cortex (V1)\n",
            "- **mixed3a/b** â‰ˆ V2/V4 (texture, shape processing)\n",
            "- **mixed4a** â‰ˆ Inferior Temporal (IT) cortex (object parts)\n"
        ]
    },
    {
        "cell_type": "code",
        "metadata": {},
        "execution_count": None,
        "outputs": [],
        "source": [
            "r\"\"\"\n",
            "Create Distill-style interactive HTML/CSS circuit diagram.\n",
            "\n",
            "This produces a publication-quality visualization similar to the\n",
            "Distill.pub Circuits articles, with:\n",
            "- Column layout showing layer progression\n",
            "- Hover tooltips with feature descriptions\n",
            "- Connection arrows between layers\n",
            "- Professional dark theme styling\n",
            "\n",
            "Implementation Notes:\n",
            "--------------------\n",
            "Uses pure HTML/CSS for maximum compatibility with Jupyter/Colab.\n",
            "No external JavaScript libraries required.\n",
            "\n",
            "The design follows Distill.pub visual language:\n",
            "- Clean, minimal aesthetic\n",
            "- Informative hover states\n",
            "- Clear visual hierarchy\n",
            "\n",
            "References:\n",
            "    Distill template: https://github.com/distillpub/template\n",
            "\"\"\"\n",
            "\n",
            "from IPython.display import HTML, display\n",
            "import base64\n",
            "from io import BytesIO\n",
            "from PIL import Image as PILImage\n",
            "\n",
            "\n",
            "def img_to_base64(img_array: np.ndarray) -> str:\n",
            "    r\"\"\"\n",
            "    Convert a numpy image array to base64-encoded PNG string.\n",
            "    \n",
            "    This enables embedding images directly in HTML without\n",
            "    requiring external file references.\n",
            "    \n",
            "    Args:\n",
            "        img_array: Numpy array of shape (H, W, 3) in range [0, 1]\n",
            "    \n",
            "    Returns:\n",
            "        str: Base64-encoded PNG image data\n",
            "    \"\"\"\n",
            "    img_uint8 = (np.clip(img_array, 0, 1) * 255).astype(np.uint8)\n",
            "    pil_img = PILImage.fromarray(img_uint8)\n",
            "    buffer = BytesIO()\n",
            "    pil_img.save(buffer, format='PNG')\n",
            "    return base64.b64encode(buffer.getvalue()).decode()\n",
            "\n",
            "\n",
            "def create_distill_circuit_html(\n",
            "    images: dict,\n",
            "    metadata: dict,\n",
            "    title: str = \"Feature Circuit Visualization\"\n",
            ") -> HTML:\n",
            "    r\"\"\"\n",
            "    Create a Distill-style HTML visualization of feature circuits.\n",
            "    \n",
            "    This produces an interactive, publication-quality diagram showing\n",
            "    the compositional hierarchy of neural network features.\n",
            "    \n",
            "    Design Principles:\n",
            "        - Clean, minimal aesthetic matching Distill.pub\n",
            "        - Informative hover states with feature descriptions\n",
            "        - Clear visual hierarchy (early â†’ late layers)\n",
            "        - Professional dark theme for visual impact\n",
            "    \n",
            "    Args:\n",
            "        images: Dict mapping 'layer:idx' to numpy image arrays\n",
            "        metadata: Dict mapping 'layer:idx' to description strings\n",
            "        title: Title displayed above the diagram\n",
            "    \n",
            "    Returns:\n",
            "        IPython.display.HTML: Renderable HTML widget\n",
            "    \n",
            "    Example:\n",
            "        >>> html = create_distill_circuit_html(images, metadata)\n",
            "        >>> display(html)  # Renders in notebook\n",
            "    \"\"\"\n",
            "    # Group images by layer\n",
            "    layers = {}\n",
            "    for key in images:\n",
            "        layer = key.split(':')[0]\n",
            "        if layer not in layers:\n",
            "            layers[layer] = []\n",
            "        layers[layer].append(key)\n",
            "    \n",
            "    # Sort layers by depth (early to late)\n",
            "    layer_order = ['conv2d1', 'mixed3a', 'mixed3b', 'mixed4a']\n",
            "    sorted_layers = [l for l in layer_order if l in layers]\n",
            "    \n",
            "    # CSS styles for Distill-like appearance\n",
            "    html_content = f'''\n",
            "    <style>\n",
            "        .distill-circuit-container {{\n",
            "            display: flex;\n",
            "            justify-content: space-around;\n",
            "            align-items: flex-start;\n",
            "            padding: 25px;\n",
            "            background: linear-gradient(145deg, #1e1e2f 0%, #2d2d44 100%);\n",
            "            border-radius: 16px;\n",
            "            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n",
            "            box-shadow: 0 10px 40px rgba(0,0,0,0.3);\n",
            "        }}\n",
            "        .distill-layer-column {{\n",
            "            display: flex;\n",
            "            flex-direction: column;\n",
            "            align-items: center;\n",
            "            gap: 12px;\n",
            "        }}\n",
            "        .distill-layer-title {{\n",
            "            color: #00d4ff;\n",
            "            font-size: 13px;\n",
            "            font-weight: 600;\n",
            "            margin-bottom: 8px;\n",
            "            text-transform: uppercase;\n",
            "            letter-spacing: 1.5px;\n",
            "        }}\n",
            "        .distill-layer-subtitle {{\n",
            "            color: #8892b0;\n",
            "            font-size: 10px;\n",
            "            margin-top: -8px;\n",
            "            margin-bottom: 10px;\n",
            "        }}\n",
            "        .distill-feature-node {{\n",
            "            position: relative;\n",
            "            cursor: pointer;\n",
            "            transition: all 0.25s cubic-bezier(0.4, 0, 0.2, 1);\n",
            "            border: 2px solid transparent;\n",
            "            border-radius: 10px;\n",
            "            overflow: hidden;\n",
            "            box-shadow: 0 4px 12px rgba(0,0,0,0.2);\n",
            "        }}\n",
            "        .distill-feature-node:hover {{\n",
            "            transform: scale(1.12) translateY(-4px);\n",
            "            border-color: #00d4ff;\n",
            "            box-shadow: 0 8px 25px rgba(0, 212, 255, 0.4);\n",
            "            z-index: 100;\n",
            "        }}\n",
            "        .distill-feature-node img {{\n",
            "            width: 85px;\n",
            "            height: 85px;\n",
            "            display: block;\n",
            "        }}\n",
            "        .distill-tooltip {{\n",
            "            display: none;\n",
            "            position: absolute;\n",
            "            bottom: calc(100% + 12px);\n",
            "            left: 50%;\n",
            "            transform: translateX(-50%);\n",
            "            background: rgba(10, 10, 20, 0.95);\n",
            "            color: #e6e6e6;\n",
            "            padding: 12px 14px;\n",
            "            border-radius: 8px;\n",
            "            font-size: 11px;\n",
            "            line-height: 1.5;\n",
            "            width: 200px;\n",
            "            text-align: center;\n",
            "            z-index: 101;\n",
            "            box-shadow: 0 6px 20px rgba(0,0,0,0.4);\n",
            "            border: 1px solid rgba(0, 212, 255, 0.2);\n",
            "        }}\n",
            "        .distill-tooltip::after {{\n",
            "            content: '';\n",
            "            position: absolute;\n",
            "            top: 100%;\n",
            "            left: 50%;\n",
            "            transform: translateX(-50%);\n",
            "            border: 10px solid transparent;\n",
            "            border-top-color: rgba(10, 10, 20, 0.95);\n",
            "        }}\n",
            "        .distill-feature-node:hover .distill-tooltip {{\n",
            "            display: block;\n",
            "            animation: fadeIn 0.2s ease-out;\n",
            "        }}\n",
            "        @keyframes fadeIn {{\n",
            "            from {{ opacity: 0; transform: translateX(-50%) translateY(5px); }}\n",
            "            to {{ opacity: 1; transform: translateX(-50%) translateY(0); }}\n",
            "        }}\n",
            "        .distill-tooltip-title {{\n",
            "            color: #00d4ff;\n",
            "            font-weight: 700;\n",
            "            font-size: 12px;\n",
            "            margin-bottom: 6px;\n",
            "        }}\n",
            "        .distill-arrow-container {{\n",
            "            display: flex;\n",
            "            align-items: center;\n",
            "            padding: 0 8px;\n",
            "        }}\n",
            "        .distill-legend {{\n",
            "            display: flex;\n",
            "            justify-content: center;\n",
            "            gap: 35px;\n",
            "            margin-top: 25px;\n",
            "            padding: 12px;\n",
            "            color: #ccd6f6;\n",
            "            font-size: 12px;\n",
            "        }}\n",
            "        .distill-legend-item {{\n",
            "            display: flex;\n",
            "            align-items: center;\n",
            "            gap: 10px;\n",
            "        }}\n",
            "        .distill-legend-color {{\n",
            "            width: 22px;\n",
            "            height: 22px;\n",
            "            border-radius: 6px;\n",
            "        }}\n",
            "        .distill-excitation {{ background: linear-gradient(135deg, #ff6b6b, #ee5a5a); }}\n",
            "        .distill-inhibition {{ background: linear-gradient(135deg, #64ffda, #45b7aa); }}\n",
            "        .distill-circuit-title {{\n",
            "            color: #ccd6f6;\n",
            "            font-size: 20px;\n",
            "            font-weight: 700;\n",
            "            text-align: center;\n",
            "            margin-bottom: 20px;\n",
            "            padding: 10px;\n",
            "        }}\n",
            "        .distill-circuit-subtitle {{\n",
            "            color: #8892b0;\n",
            "            font-size: 13px;\n",
            "            text-align: center;\n",
            "            margin-top: -15px;\n",
            "            margin-bottom: 20px;\n",
            "        }}\n",
            "    </style>\n",
            "    \n",
            "    <div style=\"background: #0a0a14; padding: 30px; border-radius: 20px;\">\n",
            "        <div class=\"distill-circuit-title\">{title}</div>\n",
            "        <div class=\"distill-circuit-subtitle\">\n",
            "            Hover over features to explore what each neuron detects\n",
            "        </div>\n",
            "        <div class=\"distill-circuit-container\">\n",
            "    '''\n",
            "    \n",
            "    # Layer descriptions\n",
            "    layer_descs = {\n",
            "        'conv2d1': 'V1-like',\n",
            "        'mixed3a': 'V2-like',\n",
            "        'mixed3b': 'V4-like',\n",
            "        'mixed4a': 'IT-like'\n",
            "    }\n",
            "    \n",
            "    # Add layer columns\n",
            "    for i, layer in enumerate(sorted_layers):\n",
            "        html_content += f'''\n",
            "            <div class=\"distill-layer-column\">\n",
            "                <div class=\"distill-layer-title\">{layer}</div>\n",
            "                <div class=\"distill-layer-subtitle\">{layer_descs.get(layer, '')}</div>\n",
            "        '''\n",
            "        \n",
            "        for key in sorted(layers[layer]):\n",
            "            img_b64 = img_to_base64(images[key])\n",
            "            desc = metadata.get(key, 'Feature visualization')\n",
            "            \n",
            "            html_content += f'''\n",
            "                <div class=\"distill-feature-node\">\n",
            "                    <img src=\"data:image/png;base64,{img_b64}\" alt=\"{key}\">\n",
            "                    <div class=\"distill-tooltip\">\n",
            "                        <div class=\"distill-tooltip-title\">{key}</div>\n",
            "                        {desc}\n",
            "                    </div>\n",
            "                </div>\n",
            "            '''\n",
            "        \n",
            "        html_content += '</div>'\n",
            "        \n",
            "        # Add arrow between layers\n",
            "        if i < len(sorted_layers) - 1:\n",
            "            html_content += '''\n",
            "                <div class=\"distill-arrow-container\">\n",
            "                    <svg width=\"35\" height=\"100\" viewBox=\"0 0 35 100\">\n",
            "                        <defs>\n",
            "                            <marker id=\"distill-arrowhead\" markerWidth=\"10\" markerHeight=\"7\" \n",
            "                                    refX=\"9\" refY=\"3.5\" orient=\"auto\">\n",
            "                                <polygon points=\"0 0, 10 3.5, 0 7\" fill=\"#64ffda\"/>\n",
            "                            </marker>\n",
            "                        </defs>\n",
            "                        <line x1=\"2\" y1=\"50\" x2=\"28\" y2=\"50\" \n",
            "                              stroke=\"#64ffda\" stroke-width=\"2\" stroke-opacity=\"0.6\"\n",
            "                              marker-end=\"url(#distill-arrowhead)\"/>\n",
            "                    </svg>\n",
            "                </div>\n",
            "            '''\n",
            "    \n",
            "    html_content += '''\n",
            "        </div>\n",
            "        <div class=\"distill-legend\">\n",
            "            <div class=\"distill-legend-item\">\n",
            "                <div class=\"distill-legend-color distill-excitation\"></div>\n",
            "                <span>Positive (Excitation)</span>\n",
            "            </div>\n",
            "            <div class=\"distill-legend-item\">\n",
            "                <div class=\"distill-legend-color distill-inhibition\"></div>\n",
            "                <span>Negative (Inhibition)</span>\n",
            "            </div>\n",
            "        </div>\n",
            "    </div>\n",
            "    '''\n",
            "    \n",
            "    return HTML(html_content)\n",
            "\n",
            "\n",
            "# Create and display Distill-style visualization\n",
            "print(\"Creating Distill-style circuit visualization...\")\n",
            "distill_viz = create_distill_circuit_html(\n",
            "    circuit_images,\n",
            "    FEATURE_METADATA,\n",
            "    title=\"ðŸ”¬ Feature Circuit: Compositional Hierarchy\"\n",
            ")\n",
            "display(distill_viz)\n",
            "print(\"\\nðŸ’¡ Tip: Hover over features to see descriptions!\")\n",
            "print(\"ðŸ“š Read more: https://distill.pub/2020/circuits/zoom-in/\")\n"
        ]
    },
    {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "### Research Implications\n",
            "\n",
            "#### Key Observations from Circuit Visualization\n",
            "\n",
            "1. **Compositional Structure**\n",
            "   - Early layers detect local, low-level features\n",
            "   - Later layers combine these into progressively more complex representations\n",
            "   - This mirrors biological visual processing (V1 â†’ V2 â†’ V4 â†’ IT)\n",
            "\n",
            "2. **Feature Families** (from Distill.pub)\n",
            "   - *Early vision*: Edges, colors, gradients\n",
            "   - *Texture*: Gabor-like, complex patterns\n",
            "   - *Parts*: Object components, shapes\n",
            "   - *Objects*: Complete object detectors\n",
            "\n",
            "3. **Polysemantic Neurons**\n",
            "   - Individual neurons may respond to multiple features\n",
            "   - Understanding requires examining *circuits* (neuron combinations)\n",
            "\n",
            "#### Mathematical Framework\n",
            "\n",
            "The compositional nature can be formalized. For a feature $f_k^{(l)}$ at layer $l$:\n",
            "\n",
            "$$f_k^{(l)} = \\sigma\\left(\\sum_j w_{jk} \\cdot f_j^{(l-1)} + b_k\\right)$$\n",
            "\n",
            "where:\n",
            "- $w_{jk} > 0$: Feature $j$ **excites** feature $k$\n",
            "- $w_{jk} < 0$: Feature $j$ **inhibits** feature $k$\n",
            "\n",
            "This is exactly what circuits reveal: how weights connect features across layers.\n",
            "\n",
            "#### Further Exploration\n",
            "\n",
            "To dig deeper:\n",
            "1. Visualize more neurons in each layer\n",
            "2. Examine `mixed5b` for complete object detectors\n",
            "3. Trace specific circuits (e.g., car detector = windows + body + wheels)\n",
            "\n",
            "**References:**\n",
            "- Olah et al., [Zoom In: An Introduction to Circuits](https://distill.pub/2020/circuits/zoom-in/)\n",
            "- Olah et al., [An Overview of Early Vision](https://distill.pub/2020/circuits/early-vision/)\n",
            "- Olah et al., [Curve Detectors](https://distill.pub/2020/circuits/curve-detectors/)\n"
        ]
    }
]


def main():
    notebook_path = Path(__file__).parent.parent / "notebooks" / "cataluna84__segment_2_activation_max.ipynb"
    
    with open(notebook_path, "r", encoding="utf-8") as f:
        notebook = json.load(f)
    
    # Find and remove old circuit visualization cells (from previous insert)
    cells_to_remove = []
    for i, cell in enumerate(notebook["cells"]):
        if cell["cell_type"] == "markdown":
            source = "".join(cell.get("source", []))
            if "## 9. Interactive Feature Circuit" in source:
                # Found start of circuit section - mark for removal
                cells_to_remove.append(i)
        elif cell["cell_type"] == "code":
            source = "".join(cell.get("source", []))
            if "CIRCUIT_LAYERS" in source or "create_plotly_circuit_grid" in source or "create_distill_circuit_html" in source:
                cells_to_remove.append(i)
    
    # Also find related markdown cells
    for i, cell in enumerate(notebook["cells"]):
        if cell["cell_type"] == "markdown":
            source = "".join(cell.get("source", []))
            if ("Option A: Interactive Plotly" in source or 
                "Option B: Distill-Style" in source or
                "Research Implications" in source or
                "Interpretation\n\nThe circuit" in source):
                if i not in cells_to_remove:
                    cells_to_remove.append(i)
    
    # Remove old cells (in reverse order to preserve indices)
    for i in sorted(set(cells_to_remove), reverse=True):
        if i < len(notebook["cells"]):
            notebook["cells"].pop(i)
    
    # Find insertion point (before Summary section)
    insert_idx = len(notebook["cells"]) - 1
    for i, cell in enumerate(notebook["cells"]):
        if cell["cell_type"] == "markdown":
            source = "".join(cell.get("source", []))
            if "## 8. Summary" in source:
                insert_idx = i
                break
    
    # Insert enhanced cells
    for j, new_cell in enumerate(ENHANCED_CELLS):
        notebook["cells"].insert(insert_idx + j, new_cell)
    
    with open(notebook_path, "w", encoding="utf-8") as f:
        json.dump(notebook, f, indent=1)
    
    print(f"âœ… Enhanced circuit visualization with {len(ENHANCED_CELLS)} cells")
    print("   Includes:")
    print("   - Comprehensive theory & mathematical formulas")
    print("   - PEP-8 style docstrings")
    print("   - Research context & Distill.pub references")
    print("   - Biological correspondence (V1 â†’ IT)")
    print("   - Plotly + HTML/CSS visualizations")


if __name__ == "__main__":
    main()
